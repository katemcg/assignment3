{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcKLWtBQ2mWNJrF637EyBL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# pip install -r requirements.txt # uncomment to install necessary packages"
      ],
      "metadata": {
        "id": "a2fcC_UuZ7Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIUOr4RCXt2S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from parent_dir import get_parent_dir\n",
        "from model_loader import load_sentiment_model\n",
        "from preprocess_text import preprocessor\n",
        "from predict_text import predict_sentiment\n",
        "from display_results import display_table, evaluate_model\n",
        "\n",
        "## USER-- choose a model between [\"model_conv\", \"model_glove\", \"model_bert\"] and input it in the space below exactly as shown\n",
        "## eg. model_name = \"model_conv\"\n",
        "model_name = \" \" # INPUT HERE\n",
        "sentiment_model = load_sentiment_model(get_parent_dir(os.getcwd()) + '/models/' + model_name + '.h5')\n",
        "\n",
        "# Load test data csv\n",
        "test_data = pd.read_csv(get_parent_dir(os.getcwd()) + \"/data/test_sample.csv\")\n",
        "test_reviews = test_data.review  # Reviews to predict on\n",
        "\n",
        "# Preprocessing images\n",
        "preprocessed_data = preprocessor(test_reviews)[0]\n",
        "\n",
        "# Makeing predictions\n",
        "predictions = predict_sentiment(preprocessed_data, sentiment_model)\n",
        "\n",
        "# Comparing with ground truth sentiments\n",
        "ground_truth = test_data.sentiment\n",
        "display_table(test_reviews, predictions, ground_truth)\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "evaluate_model(ground_truth, predictions)"
      ]
    }
  ]
}
